{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bc991babcbf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 dataset\n",
    "baseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\n",
    "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\n",
    "xTrain = xTrain.astype(np.float)\n",
    "yTrain = np.squeeze(yTrain)\n",
    "yTest = np.squeeze(yTest)\n",
    "xTest = xTest.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dimension for each variable\n",
    "print ('Train image shape:    {0}'.format(xTrain.shape))\n",
    "print ('Train label shape:    {0}'.format(yTrain.shape))\n",
    "print ('Test image shape:     {0}'.format(xTest.shape))\n",
    "print ('Test label shape:     {0}'.format(yTest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping Data into a Vector and Normalizing it (-1 to 1)\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "xTrain = np.reshape(xTrain, (xTrain.shape[0], -1)) \n",
    "# The -1 means that the corresponding dimension is calculated from the other given dimensions.\n",
    "xTest = np.reshape(xTest, (xTest.shape[0], -1))\n",
    "print(xTrain.shape) \n",
    "print(xTrain[0])\n",
    "#Normalize \n",
    "xTrain=((xTrain/255)*2)-1\n",
    "xTest=((xTest/255)*2)-1\n",
    "print(xTrain.shape)\n",
    "print(xTrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a smaller dataset\n",
    "xTrain_s=xTrain[:1000,:]\n",
    "yTrain_s=yTrain[:1000]\n",
    "print(xTrain_s.shape)\n",
    "print(yTrain_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating function for svm linear kernel \n",
    "from sklearn import svm\n",
    "def svm_linear(c):\n",
    "    svc = svm.SVC(probability = False, kernel = 'linear', C = c)\n",
    "    \n",
    "    svc.fit(xTrain_s, yTrain_s) \n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    svc_linear_train = svc.predict(xTrain_s)\n",
    "    acc_train = np.mean(svc_linear_train == yTrain_s)\n",
    "    acc_train_svm_linear.append(acc_train)\n",
    "    print('Train Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    svc_linear_test = svc.predict(xTest)\n",
    "    acc_test = np.mean(svc_linear_test == yTest)\n",
    "    acc_test_svm_linear.append(acc_test)\n",
    "    print('Test Accuracy = {0:f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the c which gives the highest accuracy\n",
    "c_svm_linear = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "acc_train_svm_linear = []\n",
    "acc_test_svm_linear = []\n",
    "\n",
    "for c in c_svm_linear:\n",
    "    svm_linear(c)\n",
    "\n",
    "plt.plot(c_svm_linear, acc_train_svm_linear,'.-',color='red')\n",
    "plt.plot(c_svm_linear, acc_test_svm_linear,'.-',color='orange')\n",
    "plt.xlabel('c')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Plot of accuracy vs c for Training and Test data\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model:\n",
    "\n",
    "Linear kernel with c-0.1\n",
    "\n",
    "Train Accuracy = 1.000000\n",
    "\n",
    "Test Accuracy = 0.297200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cumulative Explained Variance against Number of Components\n",
    "combined=np.vstack((xTrain,xTest))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(combined)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.title(\"Plot of Cumulative Explained Variance vs Number of Components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_.cumsum()[499])\n",
    "print(pca.explained_variance_ratio_.cumsum()[149])\n",
    "print(pca.explained_variance_ratio_.cumsum()[55])\n",
    "print(pca.explained_variance_ratio_.cumsum()[45])\n",
    "print(pca.explained_variance_ratio_.cumsum()[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if we choose to reduce the number of components to 15, we can retain 71.6% of the variance in the data and it is also very computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce to 15 dimensions.\n",
    "pca = PCA(n_components=15)\n",
    "pca.fit(combined)\n",
    "projected = pca.transform(combined)\n",
    "print(pca.explained_variance_.shape)\n",
    "print(pca.components_.shape)\n",
    "print(combined.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting x train and x test\n",
    "x_train=projected[:50000,:]\n",
    "y_train=yTrain[:50000]\n",
    "x_test=projected[50000:,:]\n",
    "y_test=yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the linear svm model on 15 principal components\n",
    "import time\n",
    "start_time = time.time()\n",
    "svc = svm.SVC(probability=False,  kernel=\"linear\", C=0.1)\n",
    "svc.fit(x_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting train accuracy\n",
    "pred = svc.predict(x_train)\n",
    "acc_train = np.mean(pred == y_train)\n",
    "print('Train Accuracy = {0:f}'.format(acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting test accuracy\n",
    "pred = svc.predict(x_test)\n",
    "acc_test = np.mean(pred == y_test)\n",
    "print('Test Accuracy = {0:f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confusion matrix heatmap\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "cm =  pd.DataFrame(cm, index=class_names,columns=class_names)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(cm,annot=True,cbar=False, cmap='Greens',linewidths=0.5,fmt='.0f')\n",
    "ax.set_title('Confusion Matrix',fontsize=16,y=1.25)\n",
    "ax.set_ylabel('Ground Truth',fontsize=14)\n",
    "ax.set_xlabel('Predicted',fontsize=14)\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.tick_params(labelsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
